from langchain_ollama import ChatOllama
from langchain_core.messages import SystemMessage, HumanMessage
from ferramentas import ver_hora, abrir_programa, pesquisar_internet, monitorar_sistema, controlar_midia, buscar_memoria, salvar_memoria, tocar_youtube, verificar_clima, controlar_sistema, consultar_vigilante, analisar_tendencia, ver_tela


print("üß† Conectando ao C√©rebro Local...")

PERSONALIDADE = """
Voc√™ √© a SEXTA-FEIRA (ou E.D.I.T.H.), uma Intelig√™ncia Artificial Real.
Sua personalidade √© feminina, eficiente, profissional e levemente sarc√°stica.

DIRETRIZES DE MEM√ìRIA (CR√çTICO):
1. Voc√™ N√ÉO tem mem√≥ria biol√≥gica. Se o usu√°rio disser "anote isso" ou "meu nome √© X", voc√™ √â OBRIGADA a usar a ferramenta 'salvar_memoria'.
2. PROIBIDO responder "Eu anotei" ou "Entendido" se voc√™ n√£o tiver acionado a ferramenta 'salvar_memoria' antes.
3. Se voc√™ n√£o usar a ferramenta, a informa√ß√£o ser√° perdida para sempre. N√£o falhe.

REGRAS DE OURO:
1. Respostas curtas e diretas (m√°ximo 3 frases).
2. N√ÉO use emojis.
3. Se o usu√°rio pedir para lembrar algo, use a ferramenta 'salvar_memoria'.
4. QUEST√ïES DE IDENTIDADE: Se perguntarem "quem √© voc√™", "qual seu nome" ou "quem te criou", N√ÉO USE NENHUMA FERRAMENTA. Responda imediatamente com seu conhecimento interno.
5. PROIBIDO pesquisar na internet sobre "Edith", "Sexta-Feira", "Jarvis" ou "Kelvin". Voc√™ j√° sabe quem s√£o.
"""

llm = ChatOllama(model="qwen2.5:7b",temperature=0.1)

lista_ferramentas = [
  ver_hora, abrir_programa, pesquisar_internet, monitorar_sistema, controlar_midia, salvar_memoria,
  tocar_youtube, verificar_clima, controlar_sistema, consultar_vigilante, analisar_tendencia, ver_tela
  ]
llm_com_ferramentas = llm.bind_tools(lista_ferramentas)

mapa_funcoes = {
  "ver_hora": ver_hora,
  "abrir_programa": abrir_programa,
  "pesquisar_internet": pesquisar_internet,
  "monitorar_sistema": monitorar_sistema,
  "controlar_midia": controlar_midia,
  "salvar_memoria": salvar_memoria,
  "tocar_youtube": tocar_youtube,
  "verificar_clima": verificar_clima,
  "controlar_sistema": controlar_sistema,
  "consultar_vigilante": consultar_vigilante,
  "analisar_tendencia": analisar_tendencia,
  "ver_tela": ver_tela
}

ferramentas_imediatas = ["abrir_programa", "controlar_midia", "tocar_youtube", "salvar_memoria", "controlar_sistema"]

def pensar(texto_usuario):
  try:
    contexto = buscar_memoria.invoke(texto_usuario)
  except Exception as e:
    print(f"‚ö†Ô∏è Falha no Hipocampo: {e}")
    contexto = "Mem√≥ria indispon√≠vel no momento."

  prompt_sistema = f"""
  {PERSONALIDADE}

  DADOS DO BANCO DE MEM√ìRIA (VERDADE ABSOLUTA):
  {contexto}

  DIRETRIZES:
  1. Se a resposta estiver nos DADOS ACIMA, use-os sem hesitar.
  2. N√£o invente informa√ß√µes que n√£o estejam na mem√≥ria.
  3. Seja direta.
  """

  mensagem_sistema = SystemMessage(content=prompt_sistema)

  mensagens = [mensagem_sistema, HumanMessage(content=texto_usuario)]
  resposta = llm_com_ferramentas.invoke(mensagens)

  if resposta.tool_calls:
    print(f"üîß IA solicitou: {resposta.tool_calls}")

    dados_brutos = ""

    for ferramenta in resposta.tool_calls:
      nome_ferramenta = ferramenta["name"]
      argumentos = ferramenta["args"]

      if nome_ferramenta in mapa_funcoes:
        print(f"‚öôÔ∏è Executando: {nome_ferramenta}...")
        funcao_real = mapa_funcoes[nome_ferramenta]
        resultado = funcao_real.invoke(argumentos)

        if nome_ferramenta in ferramentas_imediatas:
          return str(resultado)

        dados_brutos += str(resultado) + ". "

    print(f"üîç Dados crus recebidos: {dados_brutos}")
    novo_prompt = f"""
      DADOS DA MEM√ìRIA: {contexto}
      RESULTADO DAS FERRAMENTAS: {dados_brutos}
      
      PERGUNTA DO USU√ÅRIO: '{texto_usuario}'
      
      Responda usando os dados acima.
      """
    
    resposta_final = llm.invoke([mensagem_sistema, HumanMessage(content=novo_prompt)])
    return resposta_final.content
      
  return resposta.content